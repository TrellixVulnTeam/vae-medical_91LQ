{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cjIFrxl4xpb"
   },
   "source": [
    "# Unsupervised Anomaly Detection Brain-MRI\n",
    "\n",
    "Jupyter notebook for running all the experiments from our [paper](https://arxiv.org/abs/2004.03271). \n",
    "\n",
    "Hyperparameters may have to be adjusted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcltK7e6r5A"
   },
   "source": [
    "## Preperation\n",
    "\n",
    "### Imports and installation of the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LI-mX3ic4zBC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import os, glob\n",
    "! pip install pynrrd\n",
    "! pip install SimpleITK\n",
    "! pip install bunch\n",
    "! pip install nibabel\n",
    "! pip install medpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlBFG8cb9zRr"
   },
   "source": [
    "### Get Code\n",
    "Clone Code from github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmL1urt8-F1a"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/StefanDenn3r/Unsupervised_Anomaly_Detection_Brain_MRI\n",
    "! cd Unsupervised_Anomaly_Detection_Brain_MRI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo5Rut3WcSHH"
   },
   "source": [
    "### Google Drive mount\n",
    "Mounting Google Drive to access datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBFA_7f5cUe0"
   },
   "outputs": [],
   "source": [
    "drive.mount('gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRn8HOi7rSvV"
   },
   "source": [
    "### Tensorboard and tunneling\n",
    "Install ngrok for tunneling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc71w6qerQtF"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
    "  os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "\n",
    "if os.path.exists(\"ngrok\"):\n",
    "  os.remove(\"ngrok\")\n",
    "  \n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQ6JZY18fS4G"
   },
   "source": [
    "Start tensorboard and forward port with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kele9MJBfAVK"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'logs/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fGr1nvVqduU"
   },
   "source": [
    "Extract ngrok url for accessing tensorboard\n",
    "\n",
    "**Attention**: Sometimes it throws an error like this:\n",
    "```\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "```\n",
    "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOJxnfekqPg2"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tools.huawei.com/pypi/simple\n",
      "Requirement already satisfied: pynrrd in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from pynrrd) (1.19.2)\n",
      "Looking in indexes: http://mirrors.tools.huawei.com/pypi/simple\n",
      "Requirement already satisfied: SimpleITK in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (2.0.2)\n",
      "Looking in indexes: http://mirrors.tools.huawei.com/pypi/simple\n",
      "Requirement already satisfied: bunch in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (1.0.1)\n",
      "Looking in indexes: http://mirrors.tools.huawei.com/pypi/simple\n",
      "Requirement already satisfied: nibabel in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from nibabel) (20.9)\n",
      "Requirement already satisfied: numpy>=1.14 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from nibabel) (1.19.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
      "Looking in indexes: http://mirrors.tools.huawei.com/pypi/simple\n",
      "Requirement already satisfied: medpy in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from medpy) (1.19.2)\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from medpy) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\application\\anaconda3\\envs\\cae-gan\\lib\\site-packages (from medpy) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install pynrrd\n",
    "! pip install SimpleITK\n",
    "! pip install bunch\n",
    "! pip install nibabel\n",
    "! pip install medpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Work\\\\cae-gan\\\\MIA21_Unsupervised_Anomaly_Detection_Brain_MRI-master',\n",
       " 'D:\\\\Work\\\\labelme-v4.5.6-brush',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\python38.zip',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\DLLs',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib',\n",
       " 'D:\\\\Application\\\\Anaconda3',\n",
       " '',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'D:\\\\Application\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\l00596897\\\\.ipython']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.sys.executable\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8QsqbYA53MI"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1xgAd-K4Q30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import start!!!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-183a8ff5baf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_config_setup\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAE\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAE\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\cae-gan\\MIA21_Unsupervised_Anomaly_Detection_Brain_MRI-master\\utils\\default_config_setup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBRAINWEB\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBRAINWEB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSISBI2015\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSISBI2015\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSLUB\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSLUB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\cae-gan\\MIA21_Unsupervised_Anomaly_Detection_Brain_MRI-master\\dataloaders\\BRAINWEB.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMINC\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_center\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfrecord_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\cae-gan\\MIA21_Unsupervised_Anomaly_Detection_Brain_MRI-master\\utils\\MINC.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNII\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x \n",
    "print(\"import start!!!\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets\n",
    "from trainers.AE import AE\n",
    "from trainers.VAE import VAE\n",
    "from trainers.CE import CE\n",
    "from trainers.ceVAE import ceVAE\n",
    "from trainers.VAE_You import VAE_You\n",
    "from trainers.GMVAE import GMVAE\n",
    "from trainers.GMVAE_spatial import GMVAE_spatial\n",
    "from trainers.fAnoGAN import fAnoGAN\n",
    "from trainers.ConstrainedAAE import ConstrainedAAE\n",
    "from trainers.ConstrainedAE import ConstrainedAE\n",
    "from trainers.AnoVAEGAN import AnoVAEGAN\n",
    "from models import autoencoder, variational_autoencoder, context_encoder_variational_autoencoder, variational_autoencoder_Zimmerer, context_encoder_variational_autoencoder, context_encoder_variational_autoencoder_Zimmerer,  gaussian_mixture_variational_autoencoder_You, gaussian_mixture_variational_autoencoder_spatial, gaussian_mixture_variational_autoencoder, fanogan, fanogan_schlegl, constrained_autoencoder, constrained_adversarial_autoencoder, constrained_adversarial_autoencoder_Chen, anovaegan\n",
    "from utils import Evaluation\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets, Dataset\n",
    "\n",
    "print(\"import finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xogLARJl_B0K"
   },
   "source": [
    "Set paths to datasets and where to save checkpoints and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgkGf2LO35hI"
   },
   "outputs": [],
   "source": [
    "def get_CONFIG(timestamp=None):\n",
    "  current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "  if timestamp:\n",
    "    current_time=timestamp\n",
    "  dataset_root = \"/content/gdrive/data\"\n",
    "  save_dir = \"/content/gdrive/saved\"\n",
    "  CONFIG = {\n",
    "    \"BRAINWEBDIR\": os.path.join(dataset_root, 'Brainweb'),\n",
    "    \"MSSEG2008DIR\": os.path.join(dataset_root, 'MSSEG2008'),\n",
    "    \"MSISBI2015DIR\": os.path.join(dataset_root, 'ISBIMSlesionChallenge'),\n",
    "    \"MSLUBDIR\": os.path.join(dataset_root, 'MSlub'),\n",
    "    \"CHECKPOINTDIR\": os.path.join(save_dir, 'checkpoints', current_time),\n",
    "    \"SAMPLEDIR\": os.path.join(save_dir, 'sample_dir', current_time),\n",
    "  }\n",
    "  return CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L41jcwBrqkev"
   },
   "source": [
    "### Manual Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-a9c5c4qaiK"
   },
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Q8IFuKHqEiI"
   },
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBobdPWvXBsl"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-pIg1uHQufK"
   },
   "source": [
    "**VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia25A9wli8d6"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2WmjqCqp3S4"
   },
   "source": [
    "#### ceVAE - Variations\n",
    "\n",
    "Paper: [Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection](https://arxiv.org/abs/1812.05941)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsxKL2xIXhrL"
   },
   "source": [
    "**CE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ed4PbNOc2P50"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=CE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = CE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlPoFhpyLgqs"
   },
   "source": [
    "**ceVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ujv7TbWVuA5"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.use_gradient_based_restoration = 0.002\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder.context_encoder_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruwGvgCnuPQ8"
   },
   "source": [
    "**VAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtNu_izGM8FO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder_Zimmerer.variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9lhvpN6mu7QT"
   },
   "source": [
    "**ceVAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szrN4m0eu6xM"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=1, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder_Zimmerer.context_encoder_variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Oc6ISRcqJMI"
   },
   "source": [
    "#### GMVAE-(Restoration)-Variations\n",
    "\n",
    "Paper: [Unsupervised Lesion Detection via Image Restoration with a Normative Prior](https://openreview.net/forum?id=S1xg4W-leV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZmw9-2HO61B"
   },
   "source": [
    "**VAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAF3eVrCPAdG"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE_You, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE_You(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhllMocWpww9"
   },
   "source": [
    "**GMVAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmRGUPN86DTX"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 1\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_You.gaussian_mixture_variational_autoencoder_You)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azCAeseN3t6i"
   },
   "source": [
    "**GMVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5HNY5v-qCxO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 128\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE(tf.Session(), config, network=gaussian_mixture_variational_autoencoder.gaussian_mixture_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_GIxM1KGN2-"
   },
   "source": [
    "**GMVAE-spatial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9G0foovGNWI"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_spatial.gaussian_mixture_variational_autoencoder_spatial)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdIb36bv-yji"
   },
   "source": [
    "#### f-AnoGAN\n",
    "\n",
    "Paper: [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks.](https://www.ncbi.nlm.nih.gov/pubmed/30831356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3h_nH3F-0PP"
   },
   "source": [
    "**Unified f-AnoGan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj70VsVlAjIj"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan.fanogan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JP-2nm-jYBuQ"
   },
   "source": [
    "**f-AnoGAN - Schlegl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hclZeagWA6Rf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[16, 16], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan_schlegl.fanogan_schlegl)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0D7zuB62DR0"
   },
   "source": [
    "#### Constrained Adversarial AE\n",
    "\n",
    "Paper: [Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders](https://arxiv.org/abs/1806.04972)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh6Tvwe02OWA"
   },
   "source": [
    "**constrained AAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPBnr3r32LGf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder.constrained_adversarial_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mR-WjhNv0Mo"
   },
   "source": [
    "**constrained AAE Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_HhaHSr4Of9"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder_Chen.constrained_adversarial_autoencoder_Chen)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aMjd0DR236b"
   },
   "source": [
    "#### AnoVAEGAN\n",
    "\n",
    "Paper: [Deep autoencoding models for unsupervised anomaly segmentation in brain MR images](https://arxiv.org/abs/1804.04488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdHKBg3B2-6W"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AnoVAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AnoVAEGAN(tf.Session(), config, network=anovaegan.anovaegan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XhjDLN73NC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1-a9c5c4qaiK",
    "P2WmjqCqp3S4",
    "9Oc6ISRcqJMI",
    "qdIb36bv-yji",
    "U0D7zuB62DR0"
   ],
   "machine_shape": "hm",
   "name": "Unsupervised Anomaly Detection Brain-MRI.ipynb",
   "provenance": [
    {
     "file_id": "1SnihwKuEnP605BZEL1vdlGPA_xM6Bpgk",
     "timestamp": 1567420278659
    },
    {
     "file_id": "1Y14H2kevErX7LCln3-8yHXNQtnykb3m9",
     "timestamp": 1566387374003
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
